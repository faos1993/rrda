{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import models\n",
    "import robustness_evaluate as re\n",
    "from tqdm.notebook import tqdm\n",
    "import timm\n",
    "\n",
    "IMAGENET9_DIR = \"path_to_imagenet9_dir\"\n",
    "IMAGENET9_BGCHALLENGE_DIR = os.path.join(IMAGENET9_DIR, 'bg_challenge')\n",
    "TMETHODS = ['standard', 'standardbackground', 'rrr', 'ada', 'actdiff', 'actdiffbackground', 'gradmask', 'fgsm']\n",
    "DATASETS = ['OxfordFlower', 'CUB', 'Cars']\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def transforms_test(image, img_size):\n",
    "    if img_size == 448:\n",
    "        sizs = [512, 448]\n",
    "    elif img_size == 224:\n",
    "        sizs = [256, 224]\n",
    "    elif img_size == 128:\n",
    "        sizs = [160, 128]\n",
    "    elif img_size == 96:\n",
    "        sizs = [128, 96]\n",
    "    elif img_size == 32:\n",
    "        sizs = [48, 32]\n",
    "\n",
    "    resize = transforms.Resize(size=(sizs[0], sizs[0]))\n",
    "    image = resize(image)\n",
    "\n",
    "    #if random.random():\n",
    "    # Random crop\n",
    "    ccrop = transforms.CenterCrop(size=(sizs[1], sizs[1]))\n",
    "    image = ccrop(image)\n",
    "\n",
    "    # Transform to tensor\n",
    "    image = TF.to_tensor(image)\n",
    "\n",
    "    if image.shape[0] == 1:\n",
    "        image = torch.cat([image, image, image], dim=0)\n",
    "\n",
    "    image = TF.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "    return image\n",
    "\n",
    "class Imagenet9Challenge():\n",
    "    \n",
    "    def __init__(self, split='train', img_size=224):\n",
    "        self.dir = IMAGENET9_BGCHALLENGE_DIR\n",
    "        self.original = os.path.join(self.dir, split, 'val')\n",
    "        self.split = split\n",
    "        self.img_size = img_size\n",
    "        self.imgs = []\n",
    "        self.masks = []\n",
    "        self.targets = []\n",
    "        self.class_weights = None\n",
    "        self.load()\n",
    "    \n",
    "    def compute_class_weights(self):\n",
    "        self.class_weights = np.zeros(len(set(self.targets)))\n",
    "        one_based = 1 * (np.array(self.targets).min() == 1)\n",
    "        \n",
    "        if one_based:\n",
    "            for i in range(len(self.targets)):\n",
    "                self.targets[i] = self.targets[i] - one_based\n",
    "\n",
    "        for c in self.targets:\n",
    "            self.class_weights[c] += 1\n",
    "\n",
    "        total = self.class_weights.sum()\n",
    "        self.class_weights = self.class_weights/total\n",
    "\n",
    "    def load(self):\n",
    "        path_images = self.original\n",
    "        for idx, folder in enumerate(sorted(os.listdir(path_images))):\n",
    "            class_dir = os.path.join(path_images, folder)\n",
    "            for img in os.listdir(class_dir):\n",
    "                path_img_orig = os.path.join(class_dir, img)\n",
    "                if '.npy' in path_img_orig:\n",
    "                    img2 = np.load(path_img_orig, allow_pickle=True)\n",
    "                elif '.jpg' in path_img_orig:\n",
    "                    img2 = Image.open(path_img_orig)\n",
    "                    img2 = np.asarray(img2)\n",
    "                elif '.JPEG' in path_img_orig:\n",
    "                    img2 = Image.open(path_img_orig)\n",
    "                    img2 = np.asarray(img2)\n",
    "                    \n",
    "                \n",
    "                self.imgs.append(img2)\n",
    "                self.targets.append(idx)\n",
    "        \n",
    "        self.num_of_categories = len(set(self.targets))\n",
    "        self.compute_class_weights()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        imgs = []\n",
    "        \n",
    "        img = Image.fromarray(self.imgs[idx])\n",
    "        y = self.targets[idx]\n",
    "        \n",
    "        \n",
    "        img = transforms_test(img, self.img_size)\n",
    "\n",
    "        if img.shape[0] == 1:\n",
    "            img = torch.cat([img, img, img], 0)\n",
    "            \n",
    "        return img, 0, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best(dataset_name, tmethod, img_size=224):\n",
    "    results_dir = f'results-{dataset_name}/'\n",
    "    best_path = None\n",
    "    best_eval = 0.0\n",
    "    for file in [f for f in os.listdir(results_dir) if tmethod in f]:\n",
    "        print(file)\n",
    "        try:\n",
    "            log_path = os.path.join(results_dir, file)\n",
    "            log = torch.load(log_path)\n",
    "            if str(img_size) in file and log['train_method'] == (tmethod+'-baseline'):\n",
    "                if log['best_eval_acc'] > best_eval:\n",
    "                    best_eval = log['best_eval_acc']\n",
    "                    best_path = log_path\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print('Error:',e)\n",
    "            continue\n",
    "    print()\n",
    "    print('best path'.upper(), best_path)\n",
    "    print('accuracy:'.upper(), best_eval)\n",
    "\n",
    "    return best_path, best_eval\n",
    "\n",
    "\n",
    "def get_model_from_path(path, num_of_categories):\n",
    "    summary = torch.load(path)\n",
    "    keys = summary.keys()\n",
    "    #print(keys)\n",
    "    print('Train method:', summary['train_method'])\n",
    "    print('Best eval acc:', summary['best_eval_acc'])\n",
    "    print('regularizer_rate', summary['regularizer_rate'])\n",
    "    \n",
    "    if summary['regularizer_rate'] == 100.0:\n",
    "        r = 'r3'\n",
    "    elif summary['regularizer_rate'] == 10.0:\n",
    "        r = 'r2'\n",
    "    else:\n",
    "        r = 'r1'\n",
    "    device = 'cuda'\n",
    "\n",
    "    def printnorm(self, input, output):\n",
    "        self.avgoutput = output\n",
    "        \n",
    "    # Set model\n",
    "    #model = models.get_resnet18(num_classes=num_of_categories, pretrained=False)\n",
    "    #model.load_state_dict(summary['best_ckp'])\n",
    "    #model.avgpool.register_forward_hook(printnorm)\n",
    "    #model.to(device)\n",
    "    \n",
    "    model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=num_of_categories)\n",
    "    model.load_state_dict(summary['best_ckp'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    return model, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "dataset_name = 'Imagenet9'\n",
    "name2models = {}\n",
    "num_of_categories = 9\n",
    "\n",
    "for m in ['standard', 'standardbackground', 'actdiff', 'gradmask', 'actdiffbackground', 'ada', 'rrr']:\n",
    "    try:\n",
    "        path, acc = get_best(dataset_name, m)\n",
    "        name2models[m] = get_model_from_path(path, num_of_categories)[0]\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('challenges:'.upper())\n",
    "for challenge in os.listdir():\n",
    "    print('\\t', challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def evaluate_std(model, dataloader, criterion):            \n",
    "    model.eval()  \n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    target_labels = []\n",
    "    cat_preds = []\n",
    "\n",
    "    bar = tqdm(dataloader)\n",
    "    vec_logits = []\n",
    "    \n",
    "    for inputs, blob, labels in bar:\n",
    "        dataset_size += inputs.shape[0]\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "            \n",
    "        blob = torch.FloatTensor(blob.float()).to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        vec_logits.append(outputs.cpu().detach().numpy())\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # statistics\n",
    "        running_loss += float(loss.detach().cpu().data) * int(inputs.size(0))\n",
    "        running_corrects += float(torch.sum(preds.cpu().detach().data == labels.cpu().detach().data))\n",
    "        \n",
    "        cat_preds.extend(preds.cpu().detach().data.tolist())\n",
    "        target_labels.extend(labels.cpu().detach().data.tolist())\n",
    "    \n",
    "    vec_logits = np.concatenate(vec_logits, 0)\n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_acc = running_corrects / dataset_size\n",
    "\n",
    "    summary = {\n",
    "        #'epoch_loss':epoch_loss,\n",
    "        #'epoch_acc':epoch_acc,\n",
    "        'target_labels':target_labels,\n",
    "        'predictions':cat_preds,\n",
    "        'logits':vec_logits.tolist()\n",
    "        }\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log with confusion matrix and logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import utils_train\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(\"challenge-logits/\", exist_ok=True)\n",
    "\n",
    "NUM_WORKERS = 1\n",
    "BATCH_SIZE = 128\n",
    "img_size = 224\n",
    "#tmp_logs = []\n",
    "\n",
    "for challenge in os.listdir(IMAGENET9_BGCHALLENGE_DIR):\n",
    "    test_dataset = Imagenet9Challenge(challenge, img_size)\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True, \n",
    "        num_workers=NUM_WORKERS*2\n",
    "    )\n",
    "\n",
    "    num_of_categories = test_dataset.num_of_categories\n",
    "    print(challenge.upper())\n",
    "    for name in name2models.keys():\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        model = name2models[name]\n",
    "        ans = evaluate_std(\n",
    "                model=model, \n",
    "                dataloader=test_dataloader, \n",
    "                criterion=criterion\n",
    "                )\n",
    "        #tmp_logs.append(ans)\n",
    "        print('\\t', name, accuracy_score(ans['target_labels'], ans['predictions']))        \n",
    "        tmp_path_log = f'challenge-logits/{challenge}-{name}.pkl'\n",
    "        pd.DataFrame.from_dict(ans).to_pickle(tmp_path_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import utils_train\n",
    "\n",
    "NUM_WORKERS = 1\n",
    "BATCH_SIZE = 128\n",
    "img_size = 224\n",
    "\n",
    "summary = {\n",
    "    'method':[]\n",
    "}\n",
    "\n",
    "for name in name2models.keys():\n",
    "    summary['method'].append(name)\n",
    "    \n",
    "for challenge in os.listdir('/home/work/datafolder/imagenet9/bg_challenge'):\n",
    "    summary[challenge] = []\n",
    "    test_dataset = Imagenet9Challenge(challenge, img_size)\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True, \n",
    "        num_workers=NUM_WORKERS*2\n",
    "    )\n",
    "\n",
    "    #x, mask, y = train_dataset[0]\n",
    "    num_of_categories = test_dataset.num_of_categories\n",
    "    print(challenge.upper())\n",
    "    for name in name2models.keys():\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        model = name2models[name]\n",
    "        ans = utils_train.evaluate_std(\n",
    "                model=model, \n",
    "                dataloader=test_dataloader, \n",
    "                criterion=criterion\n",
    "                )\n",
    "        print('\\t', name, ans['epoch_acc'])\n",
    "        summary[challenge].append(ans['epoch_acc'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(summary)\n",
    "df['BG-Gap'] = df['mixed_same'] - df['mixed_rand']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_pickle(\"imagenet9-challenge-results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.concat([df, df2], axis=0).to_pickle(\"challenge-results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = pd.concat([df, df2], axis=0)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import random\n",
    "\n",
    "path_challenges = IMAGENET9_BGCHALLENGE_DIR\n",
    "path_original = os.path.join(IMAGENET9_BGCHALLENGE_DIR, 'original/val')\n",
    "challenges = os.listdir(path_challenges)\n",
    "print(challenges)\n",
    "\n",
    "category = random.choice(os.listdir(path_original))\n",
    "path_category = os.path.join(path_original, category)\n",
    "img_name = random.choice(os.listdir(path_category))\n",
    "\n",
    "print(category, img_name)\n",
    "\n",
    "for cha in challenges:\n",
    "    path_tmp = f'IMAGENET9_BGCHALLENGE_DIR/{cha}/val/{category}/{img_name}'\n",
    "    print(path_tmp, os.path.exists(path_tmp))\n",
    "    #img = Image.open(path_tmp)\n",
    "    #plt.imshow(img)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
