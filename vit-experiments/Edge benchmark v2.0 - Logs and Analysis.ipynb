{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import models\n",
    "import robustness_evaluate as re\n",
    "from tqdm.notebook import tqdm\n",
    "import timm\n",
    "import random\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "IMAGENET9_DIR = \"path_to_imagenet9_dir\"\n",
    "IMAGENET9_BGCHALLENGE_DIR = os.path.join(IMAGENET9_DIR, 'bg_challenge')\n",
    "TMETHODS = ['standard', 'standardbackground', 'rrr', 'ada', 'actdiff', 'actdiffbackground', 'gradmask', 'fgsm']\n",
    "DATASETS = ['OxfordFlower', 'CUB', 'Cars']\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "1. Imagenet9Challenge\n",
    "2. IN9Joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def transforms_test(image, img_size):\n",
    "    if img_size == 448:\n",
    "        sizs = [512, 448]\n",
    "    elif img_size == 224:\n",
    "        sizs = [256, 224]\n",
    "    elif img_size == 128:\n",
    "        sizs = [160, 128]\n",
    "    elif img_size == 96:\n",
    "        sizs = [128, 96]\n",
    "    elif img_size == 32:\n",
    "        sizs = [48, 32]\n",
    "\n",
    "    resize = transforms.Resize(size=(sizs[0], sizs[0]))\n",
    "    image = resize(image)\n",
    "\n",
    "    #if random.random():\n",
    "    # Random crop\n",
    "    ccrop = transforms.CenterCrop(size=(sizs[1], sizs[1]))\n",
    "    image = ccrop(image)\n",
    "\n",
    "    # Transform to tensor\n",
    "    image = TF.to_tensor(image)\n",
    "\n",
    "    if image.shape[0] == 1:\n",
    "        image = torch.cat([image, image, image], dim=0)\n",
    "\n",
    "    image = TF.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "    return image\n",
    "\n",
    "class Imagenet9Challenge():\n",
    "    \n",
    "    def __init__(self, split='train', img_size=224):\n",
    "        self.dir = IMAGENET9_BGCHALLENGE_DIR\n",
    "        self.original = os.path.join(self.dir, split, 'val')\n",
    "        self.split = split\n",
    "        self.img_size = img_size\n",
    "        self.paths = []\n",
    "        self.imgs = []\n",
    "        self.masks = []\n",
    "        self.targets = []\n",
    "        self.class_weights = None\n",
    "        self.load()\n",
    "    \n",
    "    def compute_class_weights(self):\n",
    "        self.class_weights = np.zeros(len(set(self.targets)))\n",
    "        one_based = 1 * (np.array(self.targets).min() == 1)\n",
    "        \n",
    "        if one_based:\n",
    "            for i in range(len(self.targets)):\n",
    "                self.targets[i] = self.targets[i] - one_based\n",
    "\n",
    "        for c in self.targets:\n",
    "            self.class_weights[c] += 1\n",
    "\n",
    "        total = self.class_weights.sum()\n",
    "        #for i in range(self.class_weights.shape[0]):\n",
    "        #    self.class_weights[i] = self.class_weights[i]/total\n",
    "        self.class_weights = self.class_weights/total\n",
    "\n",
    "    def load(self):\n",
    "        path_images = self.original\n",
    "        for idx, folder in enumerate(sorted(os.listdir(path_images))):\n",
    "            #print(idx, folder)\n",
    "            class_dir = os.path.join(path_images, folder)\n",
    "            for img in os.listdir(class_dir):\n",
    "                path_img_orig = os.path.join(class_dir, img)\n",
    "                self.paths.append(path_img_orig)\n",
    "                #img2 = Image.open(path_img_orig)\n",
    "                if '.npy' in path_img_orig:\n",
    "                    img2 = np.load(path_img_orig, allow_pickle=True)\n",
    "                elif '.jpg' in path_img_orig:\n",
    "                    img2 = Image.open(path_img_orig)\n",
    "                    img2 = np.asarray(img2)\n",
    "                elif '.JPEG' in path_img_orig:\n",
    "                    img2 = Image.open(path_img_orig)\n",
    "                    img2 = np.asarray(img2)\n",
    "                    \n",
    "                \n",
    "                self.imgs.append(img2)\n",
    "                self.targets.append(idx)\n",
    "        \n",
    "        self.num_of_categories = len(set(self.targets))\n",
    "        self.compute_class_weights()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.fromarray(self.imgs[idx])\n",
    "        y = self.targets[idx]\n",
    "        \n",
    "        \n",
    "        img = transforms_test(img, self.img_size)\n",
    "\n",
    "        if img.shape[0] == 1:\n",
    "            img = torch.cat([img, img, img], 0)\n",
    "            \n",
    "        return img, 0, y\n",
    "    \n",
    "\n",
    "class IN9Joint():\n",
    "    \n",
    "    def __init__(self, img_size=224):\n",
    "        self.dir = IMAGENET9_BGCHALLENGE_DIR\n",
    "        self.img_size = img_size\n",
    "        self.modes = ['original', 'fg_mask', 'only_fg', 'mixed_rand', 'mixed_same', 'mixed_next']\n",
    "        \n",
    "        print('Loading original ...')\n",
    "        original = Imagenet9Challenge('original', 224)\n",
    "        \n",
    "        print('Loading fg mask ...')\n",
    "        fg_mask = Imagenet9Challenge('fg_mask', 224)\n",
    "        \n",
    "        print('Loading only fg ...')\n",
    "        fg_dataset = Imagenet9Challenge('only_fg', 224)\n",
    "        \n",
    "        print('Loading mixed rand ...')\n",
    "        mr_dataset = Imagenet9Challenge('mixed_rand', 224)\n",
    "        \n",
    "        print('Loading mixed same ...')\n",
    "        ms_dataset = Imagenet9Challenge('mixed_same', 224)\n",
    "        \n",
    "        print('Loading mixed next ...')\n",
    "        mn_dataset = Imagenet9Challenge('mixed_next', 224)\n",
    "        \n",
    "        self.property_dataset = {\n",
    "            'original':sorted(original.paths),\n",
    "            'fg_mask':sorted(fg_mask.paths),\n",
    "            'only_fg':sorted(fg_dataset.paths),\n",
    "            'mixed_rand':sorted(mr_dataset.paths),\n",
    "            'mixed_same':sorted(ms_dataset.paths),\n",
    "            'mixed_next':sorted(mn_dataset.paths),\n",
    "            'target':original.targets,\n",
    "        }\n",
    "        \n",
    "        self.targets = original.targets\n",
    "        self.df = pd.DataFrame.from_dict(self.property_dataset)\n",
    "        self.class_weights = None\n",
    "    \n",
    "    def compute_class_weights(self):\n",
    "        self.class_weights = np.zeros(len(set(self.targets)))\n",
    "        one_based = 1 * (np.array(self.targets).min() == 1)\n",
    "        \n",
    "        if one_based:\n",
    "            for i in range(len(self.targets)):\n",
    "                self.targets[i] = self.targets[i] - one_based\n",
    "\n",
    "        for c in self.targets:\n",
    "            self.class_weights[c] += 1\n",
    "\n",
    "        total = self.class_weights.sum()\n",
    "        #for i in range(self.class_weights.shape[0]):\n",
    "        #    self.class_weights[i] = self.class_weights[i]/total\n",
    "        self.class_weights = self.class_weights/total\n",
    "\n",
    "    def load_img(self, path):\n",
    "        path_img_orig = path\n",
    "        \n",
    "        if '.npy' in path_img_orig:\n",
    "            img2 = np.load(path_img_orig, allow_pickle=True)\n",
    "        elif '.jpg' in path_img_orig:\n",
    "            img2 = Image.open(path_img_orig)\n",
    "            img2 = np.asarray(img2)\n",
    "        elif '.JPEG' in path_img_orig:\n",
    "            img2 = Image.open(path_img_orig)\n",
    "            img2 = np.asarray(img2)\n",
    "            \n",
    "        return img2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        imgs = []\n",
    "        \n",
    "        for m in self.modes:\n",
    "            img = self.load_img(self.property_dataset[m][idx])\n",
    "            img = Image.fromarray(img)\n",
    "            img = transforms_test(img, self.img_size)\n",
    "            \n",
    "            if img.shape[0] == 1:\n",
    "                img = torch.cat([img, img, img], 0)\n",
    "            \n",
    "            if m == 'fg_mask': #guarantee pixels in {0, 1} after normalization\n",
    "                img[img > 0] = 1.0\n",
    "                img[img < 0] = 0.0\n",
    "                \n",
    "            imgs.append(img)\n",
    "            \n",
    "        y = self.property_dataset['target'][idx]\n",
    "            \n",
    "        return imgs, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best(dataset_name, tmethod, img_size=224):\n",
    "    results_dir = f'results-{dataset_name}/'\n",
    "    best_path = None\n",
    "    best_eval = 0.0\n",
    "    for file in [f for f in os.listdir(results_dir) if tmethod in f]:\n",
    "        print(file)\n",
    "        try:\n",
    "            log_path = os.path.join(results_dir, file)\n",
    "            log = torch.load(log_path)\n",
    "            \n",
    "            if str(img_size) in file and log['train_method'] == (tmethod+'-baseline'):\n",
    "                if log['best_eval_acc'] > best_eval:\n",
    "                    best_eval = log['best_eval_acc']\n",
    "                    best_path = log_path\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print('Error:',e)\n",
    "            continue\n",
    "    print()\n",
    "    print('best path'.upper(), best_path)\n",
    "    print('accuracy:'.upper(), best_eval)\n",
    "\n",
    "    return best_path, best_eval\n",
    "\n",
    "\n",
    "def get_model_from_path(path, num_of_categories):\n",
    "    summary = torch.load(path)\n",
    "    keys = summary.keys()\n",
    "    #print(keys)\n",
    "    print('Train method:', summary['train_method'])\n",
    "    print('Best eval acc:', summary['best_eval_acc'])\n",
    "    print('regularizer_rate', summary['regularizer_rate'])\n",
    "    \n",
    "    if summary['regularizer_rate'] == 100.0:\n",
    "        r = 'r3'\n",
    "    elif summary['regularizer_rate'] == 10.0:\n",
    "        r = 'r2'\n",
    "    else:\n",
    "        r = 'r1'\n",
    "    device = 'cuda'\n",
    "\n",
    "    def printnorm(self, input, output):\n",
    "        self.avgoutput = output\n",
    "        \n",
    "    # Set model\n",
    "    #model = models.get_resnet18(num_classes=num_of_categories, pretrained=False)\n",
    "    #model.load_state_dict(summary['best_ckp'])\n",
    "    #model.avgpool.register_forward_hook(printnorm)\n",
    "    #model.to(device)\n",
    "    \n",
    "    model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=num_of_categories)\n",
    "    model.load_state_dict(summary['best_ckp'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    return model, r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"in9 = IN9Joint()\n",
    "tmp = Imagenet9Challenge('fg_mask', 224)\n",
    "\n",
    "dataset_name = 'Imagenet9'\n",
    "name2models = {}\n",
    "num_of_categories = 9\n",
    "#for m in ['standardbackground']:\n",
    "models = ['standard', 'standardbackground', 'actdiff', 'gradmask', 'actdiffbackground', 'ada', 'rrr']\n",
    "for m in models:\n",
    "    try:\n",
    "        path, acc = get_best(dataset_name, m)\n",
    "        name2models[m] = get_model_from_path(path, num_of_categories)[0]\n",
    "        name2models[m].eval()\n",
    "    except Exception as e:\n",
    "        print(e)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "from captum.attr import Saliency, IntegratedGradients\n",
    "import seaborn as sns\n",
    "\n",
    "def norm(x):\n",
    "    xmin = x.min()\n",
    "    xmax = x.max()\n",
    "    x = (x - xmin)/(xmax - xmin)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Resize\n",
    "import cv2\n",
    "\n",
    "def process(img):\n",
    "    return norm(img.permute((1, 2, 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeIN9():\n",
    "    \n",
    "    def __init__(self, ch_name, edge_width, img_size=224):\n",
    "        assert ch_name in ['original', 'mixed_rand', 'mixed_same', 'mixed_next']\n",
    "        self.dir = IMAGENET9_BGCHALLENGE_DIR\n",
    "        self.img_size = img_size\n",
    "        self.modes = [ch_name, 'fg_mask']\n",
    "        self.ch_name = ch_name\n",
    "        \n",
    "        print(f'Loading {ch_name} ...')\n",
    "        original = Imagenet9Challenge(ch_name, 224)\n",
    "        \n",
    "        print('Loading fg mask ...')\n",
    "        fg_mask = Imagenet9Challenge('fg_mask', 224)\n",
    "        \n",
    "        self.property_dataset = {\n",
    "            self.ch_name:sorted(original.paths),\n",
    "            'fg_mask':sorted(fg_mask.paths),\n",
    "            'target':original.targets,\n",
    "        }\n",
    "        \n",
    "        self.targets = original.targets\n",
    "        self.df = pd.DataFrame.from_dict(self.property_dataset)\n",
    "        self.class_weights = None\n",
    "        self.edge_width = edge_width\n",
    "    \n",
    "    def compute_class_weights(self):\n",
    "        self.class_weights = np.zeros(len(set(self.targets)))\n",
    "        one_based = 1 * (np.array(self.targets).min() == 1)\n",
    "        \n",
    "        if one_based:\n",
    "            for i in range(len(self.targets)):\n",
    "                self.targets[i] = self.targets[i] - one_based\n",
    "\n",
    "        for c in self.targets:\n",
    "            self.class_weights[c] += 1\n",
    "\n",
    "        total = self.class_weights.sum()\n",
    "        #for i in range(self.class_weights.shape[0]):\n",
    "        #    self.class_weights[i] = self.class_weights[i]/total\n",
    "        self.class_weights = self.class_weights/total\n",
    "\n",
    "    def load_img(self, path):\n",
    "        path_img_orig = path\n",
    "        \n",
    "        if '.npy' in path_img_orig:\n",
    "            img2 = np.load(path_img_orig, allow_pickle=True)\n",
    "        elif '.jpg' in path_img_orig:\n",
    "            img2 = Image.open(path_img_orig)\n",
    "            img2 = np.asarray(img2)\n",
    "        elif '.JPEG' in path_img_orig:\n",
    "            img2 = Image.open(path_img_orig)\n",
    "            img2 = np.asarray(img2)\n",
    "            \n",
    "        return img2\n",
    "    \n",
    "    def edge_process(self, imgs):\n",
    "        \"\"\"\n",
    "        Expect everyone as numpy array\n",
    "        \"\"\"\n",
    "        img = imgs[0]\n",
    "        mask = imgs[1]\n",
    "        #mask = imgs[1].numpy()\n",
    "        mask = mask * 255\n",
    "        mask = mask.astype(np.uint8)\n",
    "\n",
    "        kernel = np.ones((self.edge_width, self.edge_width), np.uint8)\n",
    "        kernel_dilate = np.ones((self.edge_width, self.edge_width), np.uint8)\n",
    "        \n",
    "        plt.imshow(mask.transpose((1, 2, 0)))\n",
    "        plt.show()\n",
    "        closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        image = Image.fromarray(closing.transpose((1, 2, 0)), 'RGB')\n",
    "        image = image.filter(ImageFilter.ModeFilter(size=13))\n",
    "        \n",
    "        closing = np.asarray(image).transpose((2, 0, 1))\n",
    "        mask_after_filter = closing.copy()\n",
    "        \n",
    "        plt.imshow(closing.transpose((1, 2, 0)))\n",
    "        plt.show()\n",
    "        \n",
    "        image_erode = cv2.erode(closing, kernel)\n",
    "        image_dilate = cv2.dilate(closing, kernel_dilate)\n",
    "\n",
    "        erode01 = image_erode.copy()\n",
    "        erode01[erode01 > 0] = 1\n",
    "        erode01[erode01 < 0] = 0\n",
    "\n",
    "\n",
    "        dilate01 = image_dilate.copy()\n",
    "        dilate01[dilate01 > 0] = 1\n",
    "        dilate01[dilate01 < 0] = 0\n",
    "\n",
    "        borda = erode01 * imgs[0]\n",
    "\n",
    "        background_dilate = (1 - dilate01) * imgs[0]\n",
    "        foreground_dilate = dilate01 * imgs[0]\n",
    "\n",
    "        edge = (1 - erode01) * dilate01 \n",
    "        edge_img = edge * imgs[0]\n",
    "        no_edge_img = (1 - edge) * imgs[0] \n",
    "        imgs[1] = mask_after_filter\n",
    "        \n",
    "        return imgs[0], imgs[1], no_edge_img, edge_img\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        imgs = []\n",
    "        \n",
    "        for m in self.modes:\n",
    "            img = self.load_img(self.property_dataset[m][idx])\n",
    "            \n",
    "            if len(img.shape) == 3 and img.shape[0] == 1:\n",
    "                img = np.concatenate([img, img, img], 0)\n",
    "            elif len(img.shape) == 2:\n",
    "                img = img[np.newaxis, :, :]\n",
    "                img = np.concatenate([img, img, img], 0)\n",
    "                \n",
    "            if m == 'fg_mask': #guarantee pixels in {0, 1} after normalization\n",
    "                img[img > 0] = 1.0\n",
    "                img[img < 0] = 0.0\n",
    "                \n",
    "            if img.shape == (224, 224, 3):\n",
    "                img = img.transpose((2, 0, 1))\n",
    "                \n",
    "            imgs.append(img)\n",
    "        \n",
    "        img, mask, noedge, edge = self.edge_process(imgs)\n",
    "        mask = mask * 1.0\n",
    "        mask[mask > 0] = 255.0\n",
    "        mask[mask < 0] = 0.0\n",
    "        \n",
    "        #print('mask after', mask.max(), mask.min())\n",
    "        \n",
    "        img = transforms_test(Image.fromarray(img.transpose((1, 2, 0))), self.img_size)\n",
    "        noedge = transforms_test(Image.fromarray(noedge.transpose((1, 2, 0))), self.img_size)\n",
    "        edge = transforms_test(Image.fromarray(edge.transpose((1, 2, 0))), self.img_size)\n",
    "        mask = transforms_test(Image.fromarray(mask.transpose((1, 2, 0)).astype(np.uint8)), self.img_size)\n",
    "        \n",
    "        #for idx in range(len(imgs)):\n",
    "        #    imgs[idx] = Image.fromarray(imgs[idx])\n",
    "        #    imgs[idx] = transforms_test(imgs[idx], self.img_size)\n",
    "        #print('mask after', mask.max(), mask.min())\n",
    "        \n",
    "        mask[mask > 0] = 1.0\n",
    "        mask[mask < 0] = 0.0\n",
    "            \n",
    "        y = self.property_dataset['target'][idx]\n",
    "        \n",
    "        #img, edge, noedge = self.edge_process(imgs)\n",
    "            \n",
    "        #return img, edge, noedge, y\n",
    "        return img, mask, noedge, edge, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = EdgeIN9(ch_name='original', edge_width=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(e))\n",
    "print(idx)\n",
    "#idx = 1507\n",
    "img, mask, noedge, edge, y = e[idx]\n",
    "print(\"Mask:\", mask.max(), mask.min())\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "\n",
    "axs[0].imshow(process(img))\n",
    "axs[0].set_title('Original', fontsize=18)\n",
    "\n",
    "axs[1].imshow(process(mask))\n",
    "axs[1].set_title('Mask', fontsize=18)\n",
    "\n",
    "axs[2].imshow(process(noedge))\n",
    "axs[2].set_title('No Edge', fontsize=18)\n",
    "\n",
    "axs[3].imshow(process(edge))\n",
    "axs[3].set_title('Edge', fontsize=18)\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_std(model, dataloader):            \n",
    "    model.eval()  \n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    target_labels = []\n",
    "    cat_preds = []\n",
    "\n",
    "    bar = tqdm(dataloader)\n",
    "    for inputs, mask, noedge, edge, labels in bar:\n",
    "        dataset_size += inputs.shape[0]\n",
    "        inputs = noedge\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # statistics\n",
    "        running_corrects += float(torch.sum(preds.cpu().detach().data == labels.cpu().detach().data))\n",
    "        \n",
    "        cat_preds.extend(preds.cpu().detach().data.tolist())\n",
    "        target_labels.extend(labels.cpu().detach().data.tolist())\n",
    "\n",
    "    epoch_acc = running_corrects / dataset_size\n",
    "\n",
    "    summary = {\n",
    "        'epoch_acc':epoch_acc,\n",
    "        'target_labels':target_labels,\n",
    "        'predictions':cat_preds\n",
    "        }\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"edge_summary = {}\n",
    "edge_size = 49\n",
    "modes = ['original', 'mixed_next', 'mixed_same', 'mixed_rand']\n",
    "for mode in modes:\n",
    "    print(mode.upper())\n",
    "    edge_summary[mode] = []\n",
    "    e = EdgeIN9(mode, edge_size)\n",
    "    edge_dataloader = torch.utils.data.DataLoader(\n",
    "        e,\n",
    "        batch_size=16,\n",
    "        shuffle=True, \n",
    "        num_workers=15\n",
    "    )\n",
    "    for name in name2models.keys():\n",
    "        print('\\t', name.upper())\n",
    "        ans = evaluate_std(name2models[name], edge_dataloader)\n",
    "        edge_summary[mode].append(ans['epoch_acc'])\n",
    "edge_summary['method'] = list(name2models.keys())\n",
    "\n",
    "os.makedirs('edge-smooth', exist_ok=True)\n",
    "eg = pd.DataFrame.from_dict(edge_summary)[['method', 'original', 'mixed_same', 'mixed_rand', 'mixed_next']].sort_values('method')\n",
    "eg.to_pickle(f\"edge-smooth/edgewidth-{edge_size}.pkl\")\n",
    "\n",
    "print(eg)\n",
    "\n",
    "in9_results = pd.read_pickle(\"challenge-results.pkl\").sort_values('method')\n",
    "og = in9_results[['method', 'original', 'mixed_same', 'mixed_rand', 'mixed_next']].drop([1])\n",
    "print(og)\n",
    "\n",
    "dif = {}\n",
    "for col in og.columns:\n",
    "    if col == 'method':\n",
    "        dif[col] = og[col].tolist()\n",
    "    else:\n",
    "        dif[col] = (og[col].values - eg[col].values).tolist()\n",
    "#og['method'].tolist(), eg['method'].tolist(),\n",
    "print(dif)\n",
    "pd.DataFrame.from_dict(dif)[['method', 'original', 'mixed_same', 'mixed_rand', 'mixed_next']].to_pickle(f\"edge-smooth/edgewidth-{edge_size}-diff.pkl\")\n",
    "#pd.DataFrame.from_dict(dif)[['method', 'original', 'mixed_same', 'mixed_rand', 'mixed_next']]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def join_logs():\n",
    "    dfs = []\n",
    "    \n",
    "    for width in [5, 9, 11, 13, 15, 17, 19, 21, 25, 35, 45, 49]:\n",
    "    #for width in [5, 19, 35, 49]:\n",
    "        try:\n",
    "            df = pd.read_pickle(f\"edge-smooth/edgewidth-{width}.pkl\")\n",
    "            df['width'] = [width] * len(df)\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def results(method):\n",
    "    log = join_logs()\n",
    "    log_sel = log[log['method'] == method]\n",
    "    \n",
    "    print(log_sel)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    subsets = ['original', 'mixed_same', 'mixed_rand', 'mixed_next']\n",
    "    \n",
    "    for idx, row in log_sel.iterrows():\n",
    "        rs = [row[s] for s in subsets] + [row[subsets[0]]]\n",
    "        w = row['width']\n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "              r=rs,\n",
    "              theta=subsets + [subsets[0]],\n",
    "              #fill='toself',\n",
    "              name=f'{w}',\n",
    "              \n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "      polar=dict(\n",
    "        radialaxis=dict(\n",
    "          visible=True,\n",
    "          range=[0.5, 1.0],\n",
    "          \n",
    "        )),\n",
    "      showlegend=True,\n",
    "      title=method.upper(),\n",
    "      legend_title='Edge width',\n",
    "      legend=dict(\n",
    "            yanchor=\"top\",\n",
    "            y=0.99,\n",
    "            xanchor=\"left\",\n",
    "            x=0.01\n",
    "        ),\n",
    "      legend_itemwidth=60,\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "interact(results, method=['standard', 'standardbackground', 'actdiff', 'gradmask', 'actdiffbackground', 'ada', 'rrr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def results_all():\n",
    "    log = join_logs()\n",
    "    methods = ['standard', 'standardbackground', 'actdiff', 'gradmask', 'actdiffbackground', 'ada', 'rrr']\n",
    "    subsets = ['original', 'mixed_same', 'mixed_rand', 'mixed_next']\n",
    "    cols = [1, 2, 3, 1, 2, 3, 1]\n",
    "    lines = [1, 1, 1, 2, 2, 2, 3]\n",
    "    \n",
    "    fig = make_subplots(rows=3, cols=3, specs=[[{'type': 'polar'}]*3]*3)\n",
    "    \n",
    "    for i in range(len(methods)):\n",
    "        method = methods[i]\n",
    "        c = cols[i]\n",
    "        l = lines[i]\n",
    "        \n",
    "        log_sel = log[log['method'] == method]\n",
    "\n",
    "        #print(log_sel)\n",
    "\n",
    "        for idx, row in log_sel.iterrows():\n",
    "            rs = [row[s] for s in subsets] + [row[subsets[0]]]\n",
    "            w = row['width']\n",
    "            if i == len(methods) - 1:\n",
    "                fig.add_trace(\n",
    "                    go.Scatterpolar(r=rs,theta=subsets + [subsets[0]], name=f'{w}', showlegend=True),\n",
    "                    l,\n",
    "                    c\n",
    "                )\n",
    "            else:\n",
    "                fig.add_trace(\n",
    "                    go.Scatterpolar(r=rs,theta=subsets + [subsets[0]], name=f'{w}', showlegend=False),\n",
    "                    l,\n",
    "                    c\n",
    "                )\n",
    "\n",
    "            fig.update_layout(\n",
    "              polar=dict(\n",
    "                radialaxis=dict(\n",
    "                  visible=True,\n",
    "                  range=[0.5, 1.0],\n",
    "\n",
    "                )),\n",
    "                #row=1,\n",
    "                #col=2\n",
    "              #showlegend=True\n",
    "            )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "results_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_logs().sort_values(['method', 'width']).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [5, 9, 11, 13, 15, 17, 19, 21, 25, 35, 45, 49]\n",
    "lista2 =  [5, 19, 35, 49]\n",
    "sel = join_logs().sort_values(['method', 'width'])\n",
    "mats = [sel[sel['width'] == w][['original', 'mixed_same', 'mixed_rand', 'mixed_next']].values for w in lista]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = []\n",
    "cha = 'original'\n",
    "\n",
    "for cha in ['original', 'mixed_same', 'mixed_rand', 'mixed_next']:\n",
    "    for w in lista:\n",
    "        all_cols.append(sel[sel['width'] == w][[cha]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(all_cols, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = sorted(list(set(sel['method'].tolist())))\n",
    "methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(all_cols, 1)[[0, 1, 2, 3, 6, 5, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly==5.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.imshow(\n",
    "    #np.concatenate(all_cols, 1),\n",
    "    np.concatenate(all_cols, 1)[[0, 2, 3, 4, 5, 1, 6]],\n",
    "    labels=dict(x=\"Challenges\", y=\"Methods\", color=\"Accuracy\"),\n",
    "    #x=['original', '','','','mixed_same','','','', 'mixed_rand','','','', 'mixed_next','','',''],\n",
    "    #x=['-', '-','-','-','-','-','-','-', '-','-','-','-', '-','-','-','-'],\n",
    "    y=np.array(methods)[[0, 2, 3, 4, 5, 1, 6]]\n",
    ")\n",
    "\n",
    "fig.update_xaxes(side=\"top\")\n",
    "\n",
    "print(type(fig))\n",
    "\n",
    "#fig.ax.xticks(ticks=[0, 2], labels=['Original', 'Original'])\n",
    "#plt.savefig('dataset-visualization/edge-challenge-heatmap.png', dpi=600)\n",
    "#fig.write_image('dataset-visualization/edge-challenge-heatmap.png')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# colorbar to figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Make a figure and axes with dimensions as desired.\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "ax1 = fig.add_axes([0.05, 0.80, 0.9, 0.15])\n",
    "\n",
    "# Set the colormap and norm to correspond to the data for which\n",
    "# the colorbar will be used.\n",
    "cmap = mpl.cm.cool\n",
    "cmap = mpl.cm.gist_gray\n",
    "norm = mpl.colors.Normalize(vmin=5, vmax=49)\n",
    "\n",
    "# ColorbarBase derives from ScalarMappable and puts a colorbar\n",
    "# in a specified axes, so it has everything needed for a\n",
    "# standalone colorbar.  There are many more kwargs, but the\n",
    "# following gives a basic continuous colorbar with ticks\n",
    "# and labels.\n",
    "cb1 = mpl.colorbar.ColorbarBase(\n",
    "    ax1, \n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    orientation='horizontal'\n",
    ")\n",
    "cb1.set_label('Edge width')\n",
    "plt.savefig('dataset-visualization/edge-colorbar.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Make a figure and axes with dimensions as desired.\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "ax1 = fig.add_axes([0.05, 0.80, 0.9, 0.15])\n",
    "\n",
    "# Set the colormap and norm to correspond to the data for which\n",
    "# the colorbar will be used.\n",
    "cmap = mpl.cm.cool\n",
    "cmap = mpl.cm.gist_gray\n",
    "norm = mpl.colors.Normalize(vmin=5, vmax=49)\n",
    "\n",
    "# ColorbarBase derives from ScalarMappable and puts a colorbar\n",
    "# in a specified axes, so it has everything needed for a\n",
    "# standalone colorbar.  There are many more kwargs, but the\n",
    "# following gives a basic continuous colorbar with ticks\n",
    "# and labels.\n",
    "cb1 = mpl.colorbar.ColorbarBase(\n",
    "    ax1, \n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    "    orientation='horizontal'\n",
    ")\n",
    "cb1.set_label('Edge width', fontsize=20)\n",
    "#ax1.set_xticklabels([])\n",
    "ax1.set_xlim(5, 49)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(mpl.cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.8 (NGC 20.11/Python 3.6 Conda) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
